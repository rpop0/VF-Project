
\documentclass[12pt]{report}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage[utf8x]{inputenc}
\usepackage{graphicx}
\usepackage{float}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[style=ieee, backend=biber]{biblatex}
\addbibresource{references.bib} 

\begin{document}

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 
%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------

\textsc{\LARGE West University of Timi\c soara}\\[1.5cm] % Name of your university/college
\includegraphics[scale=.2]{FMI-03[1].png}\\[1cm] % Include a department/university logo - this will require the graphicx package
\textsc{\Large Formal Verification 2023}\\[0.5cm] % Major heading such as course name
\textsc{\large Cybersecurity, Year 2}\\[0.5cm] % Minor heading such as course title

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[0.4cm]
{ \large \bfseries Reproducing the VNN-Comp'23 results of $\alpha$,$\beta$-CROWN \& nnenum on the NN4Sys benchmark.}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]
 
%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Authors:}\\
Leonard \textsc{HAN}\\ 
Rosian-Emanuel \textsc{POP}\\ 
Liviu \textsc{C\^{a}rjan}\\ 
Andrei \textsc{\c{T}ugmeanu}\\ 
\end{flushleft}

\end{minipage}\\[2cm]

% If you don't want a supervisor, uncomment the two lines below and remove the section above
%\Large \emph{Author:}\\
%John \textsc{Smith}\\[3cm] % Your name

%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------

{\large December, 2023}\\[2cm] % Date, change the \today to a set date if you want to be precise

\vfill % Fill the rest of the page with whitespace

\end{titlepage}
\section{Introduction}
This project aims to reproduce the results of the ``Verification of Neural Netowrks Comeptition 2023`` using a subset of the tools and a benchmark in order to achieve a greater understanding of steps involved in the process of formally verifying neural networks and the tools used to accomplish such verification.

\section{Theoretical Foundations}
This section briefly covers important theoretical elements which are relevant to our project.
\subsection{VNN-Comp}
This project aims to reproduce and verify the results from the 2023 edition of the Verification of Neural Networks Competition.
VNN-Comp is a competition with the goal of bringing together multiple researchers in order to work on techniques for verifying neural networks.

In recent years, machine learning has been deployed in order to solve a wide range of problems in fields such as autonomous driving, cyber security, machine vision, etc.
Since a lot of these applications are safety-critical, it is paramount that the behaviours generated by the used neural networks are understood and can be easily predicted at design time.
When talking about traditional system, their formal verification is a well understood and researched topic, but in the space of neural networks, their verification is still in it's infancy. \cite{vnncomp-2023}

\subsection{Neural Networks}
Neural Networks are a method in Artificial Intelligence that relies on "teaching" computers to process certain datasets in a way similar to how our human brain processes them.
Neural networks rely on nodes that are interconnected (Also called neurons)  that are layered in a structure that is similar to the human brain. 
Neural networks allow computers to learn from their mistakes and to be constantly improving themselves. 

Neural networks are primarily used in fields such as:
\begin{itemize}
    \item Computer Vision
    \item Speech Recognition
    \item Natural Language processing
    \item Quality control
    \item Financial prediction
\end{itemize}

Neural networks usually have networks of artificial neurons scattered across three layers: the Input layer, where the raw information is processed and categorized then passed onto the hidden layer.
These hidden layers take the input from the input layer or other hidden layer.
They then analyze the output from the previous layer and process it further before passing it on.
Finally, the output layer gives the final result of the data processing. \cite{aws-nn}

\subsection{NN4Sys}
NN4Sys, or \textit{Neural Networks for Systems} are neural networks which are applied on tasks related to computer systems with the aim of replacing certain systems with neural networks.
So far, these types of neural networks have been used for database indexing, database query optimization, memory allocation, etc.

The current issue with NN4Sys and one of the many reasons they haven't been used in practice is because they may produce outcomes which are unpredictable, such as attempting to schedule invalid jobs (In the case of a NN-based scheduler). 
One way to solve this problem is through \textbf{Neural Network Formal Verification}, which can check if a neural network satisfies the user specifications. 

One of the primary reasons that Neural Networks for systems are a prime candidate for formal verification is due to the fact that in the context of a computing system, these neural networks are usually small in size and the specifications are unambiguous. \autocite{nn4sysbench2022} 

\subsection{NN4SysBench}
NN4SysBench is a benchmark suite proposed by Haoyu He, Tianhao Wei, Huan Zhang, Changliu Liu and Cheng Tan that enables neural networks for systems to be formally verified.
NN4SysBench primarily focuses on database-related Neural Network verification, specifically providing benchmarks for \textbf{Learned index} and \textbf{Learned cardinality estimation}, but in the 2023 edition of VNN-Comp a new application was proposed to be included in this category, \textbf{Neural Adaptive Video Streaming with Pensieve}. \autocite{nn4sysbench2022}

\subsubsection{Learned index}
Indexes are data structures which allow systems, primarily databases, to quickly access data.
The input for such indexes are database keys and the outputs is the disk location of the data.
Learned index is an alternative index structure which allows a faster lookup time and a smaller memory footprint when compared to more traditional indexing data structures such as B-Trees.
This alternative structure is based on Neural Networks that learn the key distribution of databases and attempt to give accurate predictions of where the data is located on disk. \autocite{nn4sysbench2022}

\subsubsection{Learned cardinality estimation}
When a database system is attempting the optimization of a query, the system crates a query plan.
This query plan contains certain steps and operations to retrieve the data.
When optimizing a more complex query the system can break down the query plan into multiple sub-plans that are easier to manage and can be optimized on their own to improve the performance.

When creating these query plans, cardinality estimation is a very important technique that essentially estimates the size of the results of certain operations (joins, aggregations, filters) in order to help create a more optimized query plan.
Neural Networks can be used to enhance cardinality estimation and offer accurate predictions to allow for faster and more efficient query plan generation. \autocite{nn4sysbench2022}

\subsubsection{Neural Adaptive Video Streaming with Pensieve}
When streaming videos from the internet, video players use Adaptive Bitrate Algorithms to optimize the quality of the user's experience, such as lowering the bitrate to allow for a smoother watching experience when network conditions are not optimal.
Hongzi Mao, Ravi Netravali and Mohammad Alizadeh propose a system named Pensieve which can generate adaptive bitrate algorithms using a neural network which learns based observations collected by the video player.
In comparison to traditional adaptive bitrate methods, Pensieve does not make any assumptions about the environment but instead it makes all its decisions by observing the performance of its past decisions. \autocite{Pensieve2017}

\section{Formal Verification Tools}
In order to verify the neural networks provided by the NN4Sys benchmark, we chose two tools from the ones submitted for the 2023 edition of VNN-Comp: nnenum and $\alpha$,$\beta$-CROWN.

\subsection{nnenum}
The Neural Network Enumeration Tool (nnenum) is a tool used to formally verify neural networks created by Stanley Bak.
Nnenum is using multiple levels of abstraction in order to quickly verify ReLU (Rectified Linear Unit) neural networks. \autocite{bak2021nfm}
The primary reason why we decided to select nnenum as one of the tools for our project was due to its results in the 2020 edition of VNN-Comp, where it was the only tool that verified all the ACAS-Xu benchmarks in under 10 seconds.

\subsubsection{Installation}
Since nnenum is written in Python and does not require any compilation, the installation process of the tool was relatively straightforward.
The creator of the tool provided a Dockerfile for easy deployment, which we based our deployment on the tool on.

The first step we took in the nnenum installation process was to build the Docker image with the provided Dockerfile.
The author of the tool provided a suite of shell scripts to be used in VNN-Comp, scripts which we decided to write a Python wrapper around to allow us to easily execute the tool and extract the information about the runs from it.
This Python wrapper coupled with a custom \textit{docker-compose.yml} which can be found in our GitHub Repository \footnote{“Github repository containing project code.”  https://github.com/rpop0/VF-Project} is what allowed us to easily and quickly deploy the tool and run it against the VNN-Comp 2023 version of the NN4Sys benchmark.

Essentially, our Docker Compose configuration mounts the benchmark and our wrapper into the \textit{nnenum} container and runs nnenum through our wrapper against the benchmark, outputting the results for each instance. This is as simple as modifying the \textit{docker-compose.yml} to contain the paths to NN4SysBench and our Wrapper, and then simply running the command \textit{docker compose up -d}.

\subsubsection{Initial results}
During our preliminary runs of nnenum used to verify the functionality of the tool, we were able to get the same results that the tool achieved during VNN-Comp'23.
The results of these runs can be found in our GitHub Repository \footnote{“Github repository containing project code.” https://github.com/rpop0/VF-Project}, under \textit{nnenum/preliminary-runs}.
The preliminary results are comprised of multiple text files named after the instance index from the NN4SysBench \textit{instances.csv} which contain either \textbf{holds} for an UNSAT result, \textbf{violated} for a SAT result and respectively \textbf{timeout}.
Not instances are present in the results due to the fact that nnenum does not generate an output file for runs that resulted in errors.
Therefore, we have the following preliminary results:
\begin{enumerate}
    \item Instances 1 to 104 - No result
    \item Instances 105 to 126 - UNSAT
    \item Instances 127, 128 - Timeout
    \item Instances 129 to 193 - No result
\end{enumerate}
These results are in line with the results achieved by nnenum at VNN-Comp'23.

\subsection{$\alpha$$\beta$-crown} 

$\alpha$ $\beta$-crown (alpha beta crown) is a neural network verifier based on an effective bound approach and branch and bound, created by Huan Zhang and his team from CMU, UCLA. It scales to relatively large convolutional networks (e.g., millions of parameters) and can be efficiently accelerated on GPUs. In addition, it can test extra general neural network features and offer proved robustness assurances against adversarial attacks. The reason we decided to take this algorithm as the second tool for the project was the amazing performances from ``International Verification of Neural Networks Competition`` winning the competition in 2021, 2022 and 2023 with the highest total score, outperforming many other neural network verifiers on a wide range of benchmarks over 2 years.

\subsubsection{Installation}

\printbibliography
\end{document}


